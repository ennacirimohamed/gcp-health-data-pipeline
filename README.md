```markdown
# ğŸŒ GCP Health Data Pipeline

This project demonstrates how to build a data pipeline on **Google Cloud Platform** using **Apache Airflow (installed on a VM)**, **Google Cloud Storage (GCS)**, and **BigQuery**.

A CSV file containing **1 million rows** of global health data is uploaded to GCS, ingested into BigQuery, and transformed into **country-specific tables** and **reporting views** with selected fields.

---

## ğŸ“ Project Structure

```
gcp-health-data-pipeline/
â”‚
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ load_transform_reporting_dag.py
â”‚
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ create_service_account.png
â”‚   â”œâ”€â”€ create_vm.png
â”‚   â”œâ”€â”€ dag_graph.png
â”‚   â”œâ”€â”€ dag_run_logs.png
â”‚   â”œâ”€â”€ install_airflow_vm.png
â”‚   â”œâ”€â”€ service_account_roles.png
â”‚   â””â”€â”€ upload_gcs.png
â”‚
â””â”€â”€ README.md
```

---

## ğŸ—‚ï¸ Pipeline Overview

1. ğŸ“‚ Upload the CSV file to **GCS**
2. ğŸ’» Set up **Airflow** on a **Compute Engine VM**
3. ğŸ” Create a **Service Account** with access to GCS & BigQuery
4. ğŸ› ï¸ Trigger a DAG that:
   - Waits for the file in GCS
   - Loads it into a staging table in BigQuery
   - Creates filtered country-specific tables
   - Creates views with only the following columns:
     - `Country`
     - `Year`
     - `Disease Name`
     - `Disease Category`
     - `Prevalence Rate`

---

## ğŸ“¸ Step-by-Step Screenshots

### 1. Upload the CSV file to GCS

![Upload to GCS](images/upload_gcs.png)

---

### 2. Create the Virtual Machine & Install Airflow

VM Creation:

![Create VM](images/create_vm.png)

Airflow Installation:

![Install Airflow](images/install_airflow_vm.png)

---

### 3. Create the Service Account

![Create Service Account](images/create_service_account.png)

---

### 4. Assign Roles to the Service Account

![Service Account Roles](images/service_account_roles.png)

---

### 5. DAG View in Airflow UI

DAG Graph:

![DAG Graph](images/dag_graph.png)

DAG Logs:

![DAG Run Logs](images/dag_run_logs.png)

---

## âœ… Output

- Transformed tables are stored in: `transformdataset`
- Reporting views are created in: `reportingdataset`

---

## âš™ï¸ Technologies Used

- Apache Airflow
- Google Cloud Storage (GCS)
- BigQuery
- Compute Engine (VM)
- IAM (Service Accounts)
- Python

---

## ğŸ“ Author

Mohamed EN-NACIRI  
[LinkedIn](https://www.linkedin.com/in/mohamed-en-naciri-3a9988261/) | [GitHub](https://github.com/ennacirimohamed)
```
